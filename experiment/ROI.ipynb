{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cdd2f10",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e2747",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/shapedescr.cpp:315: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'contourArea'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cnt \u001b[38;5;129;01min\u001b[39;00m cnts:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Check the area of contour, if it is very small ignore it\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(cv2\u001b[38;5;241m.\u001b[39mcontourArea(cnt) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Filtered countours are detected\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/shapedescr.cpp:315: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'contourArea'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import contours\n",
    "\n",
    "image = cv2.imread('images/2.jpeg')\n",
    "original = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "canny = cv2.Canny(gray, 500, 1000, 1)\n",
    "\n",
    "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,2))\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,1))\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "erode = cv2.erode(canny, vertical_kernel)\n",
    "cv2.imshow('remove horizontal', erode)\n",
    "dilate = cv2.dilate(erode, vertical_kernel, iterations=5)\n",
    "cv2.imshow('dilate vertical', dilate)\n",
    "erode = cv2.erode(dilate, horizontal_kernel, iterations=1)\n",
    "cv2.imshow('remove vertical', erode)\n",
    "dilate = cv2.dilate(erode, kernel, iterations=4)\n",
    "cv2.imshow('dilate horizontal', dilate)\n",
    "\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "digit_contours = []\n",
    "for c in cnts:\n",
    "    area = cv2.contourArea(c)\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "    x,y,w,h = cv2.boundingRect(approx)\n",
    "    aspect_ratio = w / float(h)\n",
    "\n",
    "    if (aspect_ratio >= 0.4 and aspect_ratio <= 1.3):\n",
    "        if area > 150:\n",
    "            ROI = original[y:y+h, x:x+w]\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            digit_contours.append(c)\n",
    "\n",
    "sorted_digit_contours = contours.sort_contours(digit_contours, method='left-to-right')[0]\n",
    "contour_number = 0\n",
    "for c in sorted_digit_contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    ROI = original[y:y+h, x:x+w]\n",
    "    # cv2.imwrite('ROI_{}.png'.format(contour_number), ROI)\n",
    "    contour_number += 1\n",
    "\n",
    "cv2.imshow('canny', canny)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29a819",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd114d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 20:07:47.503 python[59119:155506500] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-05-25 20:07:47.503 python[59119:155506500] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- Optional: set up background subtractor (only relevant for live/video) ---\n",
    "bgsub = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# Read Input image\n",
    "inputImage = cv2.imread(\"./images/2.jpeg\")\n",
    "inputImageCopy = inputImage.copy()\n",
    "\n",
    "# 1) Warp/ROI isolation would go here if you had it…\n",
    "#    (we’ll just operate on the full image)\n",
    "\n",
    "# 2) Convert to grayscale + CLAHE for contrast\n",
    "gray = cv2.cvtColor(inputImage, cv2.COLOR_BGR2GRAY)\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "gray = clahe.apply(gray)\n",
    "\n",
    "# 3) Adaptive Thresholding\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "th_adapt = cv2.adaptiveThreshold(\n",
    "    blur, 255,\n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    cv2.THRESH_BINARY_INV,\n",
    "    blockSize=15,\n",
    "    C=5\n",
    ")\n",
    "\n",
    "# 4) Canny Edge Detection (optional, helps reinforce strokes)\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "edges = cv2.dilate(edges,\n",
    "    cv2.getStructuringElement(cv2.MORPH_RECT, (3,3)),\n",
    "    iterations=1\n",
    ")\n",
    "\n",
    "# 5) (Optional) combine with background‐subtraction mask\n",
    "fgmask = bgsub.apply(inputImage)\n",
    "combined = cv2.bitwise_or(th_adapt, edges)       # merge edges + threshold\n",
    "combined = cv2.bitwise_and(combined, fgmask)     # ignore background motion\n",
    "\n",
    "# 6) Morphological clean‐up\n",
    "kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "kernel5 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "clean = cv2.morphologyEx(combined, cv2.MORPH_OPEN,  kernel3, iterations=1)\n",
    "clean = cv2.morphologyEx(clean,  cv2.MORPH_CLOSE, kernel5, iterations=1)\n",
    "\n",
    "# 7) Flood-fill border (as you had) to remove edge‐touching blobs\n",
    "cv2.floodFill(clean, None, (0, 0), 0)\n",
    "\n",
    "# 8) Find external contours on the cleaned mask\n",
    "contours, _ = cv2.findContours(\n",
    "    clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    ")\n",
    "\n",
    "minArea = 5000\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if w*h < minArea:\n",
    "        continue\n",
    "\n",
    "    # square‐ify as before\n",
    "    size = max(w, h)\n",
    "    cx, cy = x + w//2, y + h//2\n",
    "    x1, y1 = max(cx-size//2, 0), max(cy-size//2, 0)\n",
    "    x2, y2 = min(x1+size, inputImage.shape[1]), min(y1+size, inputImage.shape[0])\n",
    "\n",
    "    # draw & extract\n",
    "    cv2.rectangle(inputImageCopy, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "    squareROI = inputImage[y1:y2, x1:x2]\n",
    "\n",
    "    # downscale + grayscale\n",
    "    smallROI   = cv2.resize(squareROI, (32,32), interpolation=cv2.INTER_AREA)\n",
    "    smallGray  = cv2.cvtColor(smallROI, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # display\n",
    "    cv2.imshow(\"Clean Mask\", clean)\n",
    "    cv2.imshow(\"Square Crop (orig)\", squareROI)\n",
    "    cv2.imshow(\"32x32 Gray\",     smallGray)\n",
    "    cv2.imshow(\"All Boxes\",      inputImageCopy)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c6d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
